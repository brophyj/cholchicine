{
  "hash": "0e73b0fc621876c97e12e60b84333ff4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Interpreting RCTs results\nauthors:\n  - name: James M Brophy\n    affiliation: McGill University\n    roles: conception, analysis, writing\n    orcid: 0000-0001-8049-6875\n    email: james.brophy@mcgill.ca\n    corresponding: true\nbibliography: references.bib\nabstract: |\n  **Background** Previous research has suggested a benefit for colchicine following an acute cornary syndrome. However the lastest large trial did not confirm any benefit. How to interpret these apparently conflicting results is the subect of this manuscript.         \n  \n  **Methods** A Bayesian workflow is presented.\n---\n\n\n\n\n\n\n\n\n\n\n#---\ntitle: \"The trials of interpreting clinical trials - What to believe?\"\nauthor: \n  - name: Jay Brophy\n    affiliation: McGill University\n    roles: conception, analysis, writing\n    orcid: 0000-0001-8049-6875\n    email: james.brophy@mcgill.ca\n    corresponding: true\ndate: 'December 18, 2024'\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show the code\"\n    css: custom.scss\n  pdf:\n    toc: true\n    number-sections: true\n    latex-engine: pdflatex\n    colorlinks: true\neditor: visual\ninteractive: false\nbibliography: references.bib\n\n---\n\n\n\n\n\n\n\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\n# Set global options for chunk outputs\nknitr::opts_chunk$set(\n  message = FALSE,  # Hide messages\n  warning = FALSE,  # Hide warnings\n  echo = TRUE,      # Show code\n  eval = TRUE,      # Ensure code is evaluated\n  comment = NA,     # Suppress \"In [1]:\" or similar prompts\n  results = \"markup\" # Ensure output is rendered as markup, not interactive ?\"asis\"\n)\n\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(posterior)\n  library(brms)\n  library(Rcpp)\n  library(lme4)\n})\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'Rcpp' was built under R version 4.4.1\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidyverse, quietly = T)\nlibrary(magrittr, quietly = T)\nlibrary(cmdstanr, quietly = T)\nlibrary(bayesplot,quietly = T)\nlibrary(lme4, quietly = T)\nlibrary(posterior, quietly = T)\nlibrary(brms, quietly = T)\n\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(posterior)\n  library(brms)\n})\n```\n:::\n\n\n\n\n\n\n\n\n\n## Introduction\n\nThe current evidence based medicine (EBM) paradigm places systematic reviews and meta-analyses ideally of randomized clinical trials at the top of the evidential pyramid. A much less studied, but recurring question is how to approach the situation with missing or \"conflicting\" evidence. While this commentary will explore various statistical approaches, it must be appreciated that these are but ancillary methods to the more crucial element of clinical judgement. Clinical judgement must precede statistical analyses in deciding what is in fact \"combinable\", in an analogous manner as to why statistical significance alone can't automatically equate to causality.\n\n## A recent example\n\nIn the CLEAR OASIS 9 trial[@CLEAR] acute MI patients were randomized to colchicine (n = 3,528) or placebo (n = 3,534) immediately after percutaneous coronary intervention (PCI). The primary outcome of major adverse CV events (MACE), composite of CV death, MI, stroke, or ischemia-driven revascularization, with a median 3 year follow-up was: 9.1% vs. 9.3%, hazard ratio (HR) 0.99 (95% confidence interval \\[CI\\] 0.85-1.16, p = 0.93). Also none of the prespecified clinical secondary outcomes reached clinical significance. Given the high quality of the study design and its execution combined with the large number of primary-outcome events (649), the authors reasoned that the chance of a spurious result was low. Thus, they concluded \"Among patients who had myocardial infarction, treatment with colchicine, when started soon after myocardial infarction and continued for a median of 3 years, did not reduce the incidence of the composite primary outcome.\"\\\n<br> The CLEAR authors acknowledge that the most comparable previous study was COLCOT[@RN33], a randomized colchicine trial involving 4745 patients who received colchicine at a dose of 0.5 mg daily (n=2366) or placebo within 30 days of an acute myocardial infarction and were followed for a median of 22.6 months. The composite primary outcome was a composite (cardiovascular deaths, recurrent myocardial infarction, resuscitation after cardiac arrest, stroke, or urgent hospitalization for angina that led to revascularization), similar to CLEAR. This trial had a total of 301 primary-outcome events, and colchicine treatment was associated with a 23% relative reduction (hazard ratio, 0.77; 95% confidence interval \\[CI\\], 0.61 to 0.96; P = 0.02). In the CLEAR discussion, there was no attempt to explain these \"differences\" other than observing that two other recent colchicine trials in stroke patients[@RN52][@RN53] also showed no benefit with colchicine and that CLEAR was a bigger trial, presumably with improved precision of the treatment effect.\\\n<br> What then should the average clinician now believe? Should they adopt the implicit CLEAR investigators' view that since their trial is larger it should be believed and that the evidence from the 4745 COLCOT patients should be forgotten or ignored. The CLEAR PI was more explicit in an interview following the oral presentation of these findings stating that before CLEAR \"I was a believer in colchicine,\" (implictly because of COLCOT(?), although this belief presumably wasn't universally shared or the necessary equipoise would not have been present to proceed with the CLEAR trial) but not after CLEAR \"I decided to stop it in my parent\"[@RN7043]. This dichotomization of beliefs is common, undoubtedly influenced by the null hypothesis significance testing paradigm and the conventional p value 0.05 threshold for medical research, reflecting a deterministic binary viewpoint not only for accepting or rejecting null hypotheses but also for clinical decision making.\\\n<br> Of course, some may eschew this approach and prefer to wait for a meta-analysis incorporating all available colchicine studies but care must be taken to assure the consistency of study design, patient populations, and outcomes. But what if there are no meta-analyses or even more disconcerting no previous trials? Is there another approach that may facilitate a more nuanced interpretation of the CLEAR study with, or without, the existence of prior knowledge?\\\n<br>\n\n## The Bayesian approach\n\nThe common statistical paradigm in medical research is null hypothesis significance testing (NHST) where decisions are conditioned on the comparison of p values (P (data or more extreme \\| hypothesis)[^1] to prespecified type I errors. Unfortunately this approach has been repeatedly shown to favor cognitive errors[@RN3836][@RN3826][@RN5420]. On the other hand, a Bayesian approach provides the information clinicians are actually seeking, namely the probability that the hypothesis is true given the observed data, P (hypothesis \\| observed data). This posterior distribution, derived from a weighted combination of a prior belief and the current data, not only allows the incorporation of prior knowledge, when available according to the rules of probability, but also avoids the aforementioned cognitive errors.\n\n[^1]: Shorthand for \"Probability (data or more extreme given the hypothesis)\"\n\n### Vague priors\n\nBayesian analyses can use differing prior beliefs thereby providing an assessment of the overall robustness of the posterior conclusions. Returning to the CLEAR example, let's adopt their viewpoint of interpreting the data independently of any prior knowledge. This involves choosing a vague prior so that the posterior probability distribution is completely dominated by the observed CLEAR data. Probability distribution are not restricted to specific point estimates but can be calculated for multiple different cutpoints or intervals. For example, one might assume that we are particularly interested in probabilities that exceed a clinically meaningful benefit or harm. These clinical cutpoints can be individually chosen but for demonstration purposes, let's assume a benefit threshold of RR \\< 0.9 and harm threshold of RR \\> 1.1.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data for the model\ndata_list <- list(\n  n2 = 3528,\n  y2 = as.integer(3528 * 0.091),\n  n1 = 3534,\n  y1 = as.integer(3534 * 0.093)\n)\n\n# Compile and fit the model\nmod <- cmdstan_model(\"binom_2.stan\")\nfit <- mod$sample(data = data_list, chains = 4, parallel_chains = 4,        refresh = 0, seed = 123)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extracting posterior samples\nposterior_samples <- fit$draws()\n\n# Plotting\ncolor_scheme_set(\"blue\")\nmcmc_trace(posterior_samples, pars = c(\"p1\", \"p2\", \"rr\"), nrow = 3)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: The following arguments were unrecognized and ignored: nrow\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot relative risk distributions with no formatting\n# mcmc_areas(posterior_samples, pars = \"rr\", prob = 0.95)\n\n# print summary\nfit$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 10\n  variable       mean    median      sd     mad       q5      q95  rhat ess_bulk\n  <chr>         <dbl>     <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n1 lp__     -2173.      -2.17e+3 1.04    0.726   -2.18e+3 -2.17e+3  1.00    1907.\n2 p1           0.0930   9.29e-2 0.00490 0.00474  8.51e-2  1.01e-1  1.00    3010.\n3 p2           0.0912   9.11e-2 0.00492 0.00479  8.35e-2  9.95e-2  1.00    3217.\n4 rr           0.983    9.80e-1 0.0741  0.0727   8.67e-1  1.11e+0  1.00    3183.\n# ℹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# Correct extraction of relative risk samples\nrr_samples <- fit$draws(variables = \"rr\")\nrr_vector <- as.vector(rr_samples)  # Convert to a simple vector for easier handling\n\n# Calculating probabilities\nprob_rr_less_09 <- mean(rr_vector < 0.9)\nprob_rr_between_09_11 <- mean(rr_vector >= 0.9 & rr_vector <= 1.1)\nprob_rr_greater_11 <- mean(rr_vector > 1.1)\nprob_rr_less_10 <- mean(rr_vector < 1.0)\n# Print the probabilities\noptions(digits = 2)\n #cat(\"Probability RR < 0.9: \", 100*prob_rr_less_09, \"%\" ,\"\\nProbability RR 0.9 to 1.1: \", 100*prob_rr_between_09_11, \"%\" ,\"\\nProbability RR > 1.1: \", 100*prob_rr_greater_11, \"%\" ,\"\\n\")\n```\n:::\n\n\n\n\n\n\n\n\n\nUsing the CLEAR data alone with vague priors, the probabilities of clinical benefit (RR \\< 0.9), practical equivalence ( 0.9 \\< RR \\< 1.1) and harm (RR \\> 1.1) are 12.38%, 81.2% and 6.42%, respectively. The probability of any benefit (RR , 1) is 60.45%. These results can also be shown graphically, where the area under the curve is proportional to each probability.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming rr_vector is already defined\nd <- density(rr_vector)\ndensity_df <- data.frame(x = d$x, y = d$y)\n\n# Assign categories based on the x values\ndensity_df$category <- ifelse(density_df$x < 0.9, \"benefit\",\n                              ifelse(density_df$x <= 1.1, \"equivalence\", \"harm\"))\n\np <- ggplot(density_df, aes(x = x, y = y)) +\n  geom_area(data = subset(density_df, category == \"benefit\"), fill = \"green\", alpha = 0.5) +\n  geom_area(data = subset(density_df, category == \"equivalence\"), fill = \"yellow\", alpha = 0.5) +\n  geom_area(data = subset(density_df, category == \"harm\"), fill = \"red\", alpha = 0.5) +\n  geom_vline(xintercept = 0.9, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 1.1, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 1.0, color = \"blue\", size=1.5) +\n  labs(title=\"Density Plot of Relative Risk based on CLEAR OASIS\",\n       subtitle = \"with a vague prior\") +\n  theme_classic() +\n  scale_x_continuous(expand = c(0, 0)) +  # No expansion on x-axis\n  scale_y_continuous(expand = c(0, 0)) +  # No expansion on y-axis\n  xlab(\"Relative Risk\") +\n  ylab(\"Density\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n```{.r .cell-code}\np <- p + \n  annotate(\"text\", x = 0.80, y = max(density_df$y, na.rm = TRUE) * 0.6, label = \"Green\", color = \"green\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 0.89, y = max(density_df$y, na.rm = TRUE) * 0.57, label = \" = region of clinical benefit\", color = \"black\", size = 5) +\n  annotate(\"text\", x = 0.8, y = max(density_df$y, na.rm = TRUE) * 0.8, label = \"Yellow\", color = \"yellow\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = .92, y = max(density_df$y, na.rm = TRUE) * 0.77, label = \" = region of practical equivalence\", color = \"black\", size = 5) +\n  annotate(\"text\", x = 1.1, y = max(density_df$y, na.rm = TRUE) * 0.4, label = \"Red\", color = \"red\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 1.19, y = max(density_df$y, na.rm = TRUE) * 0.37, label = \" = region of clinical harm\", color = \"black\", size = 5)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\nThis analysis shows a small, but not trivial probability (12.4%) of a clinically significant benefit (where this has been arbitrarily defined as a minimum 10% decrease in RR). There is a 6.4% of clinical harm (RR \\>1.1) and a 81.2% probability of practical equivalence.\\\n<br> Recall that this analysis considers only the current CLEAR study but a 12.% probability of an at least 10% reduction in RR may be seen by some to be more consistent with the conclusion that while unlikely the possibility of a cholchicine benefit remains and that additional studies or analyses are required rather than with the published CLEAR conclusion of not reducing the incidence of the composite primary outcome.\\\n<br> Moreover the lead CLEAR PI claimed he was a priori a \"believer\" so this vague prior should be replaced with an informative prior belief that is updated with this new data. Informative priors are combined with the current data following the laws of probability, i.e. a weighted average according with weights proportional to the precision of the prior and current data.\n\n### Informative prior\n\nGiven that CLEAR and COLCOT were both well designed, well executed trials examining the same intervention in the same study populations and published in the same esteemed medical journal, its seems absurd to completely ignore either of these studies. A more basic question then is are these two study results really different? From a substantive perspective given the same interventions in similar populations with the same measured outcome, the clinical answer appears to be that they are not different. Even from a statistical perspective the trials do not appear radically different with overlapping of the reported 95% confidence intervals for the primary outcomes. It is only each trial is assessed with the dichotomous statistical significance lens that the two trials appear different and there is no reason why this ersatz statistical heterogeneity should prevail. The error with this approach have been previously well documented with the key insight being \"In making a comparison between two treatments, one should look at the statistical significance of the difference rather than the difference between their significance levels[@RN5721]. The Bayesian statistical lens will clarify these shortcomings.\n\nCOLCOT results may also be analyzed and presented within a Bayesian framework, again with a vague prior so the results are dependent uniquely on the observed data. This may help in understanding why before CLEAR, some were \"colchicine believers\" and other were not.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data for the COLCOT model\ndata_list1 <- list(\n  n2 = 2366,\n  y2 = as.integer(2366 * 0.055),\n  n1 = 2379,\n  y1 = as.integer(2379 * 0.071)\n)\n\n# Compile and fit the model\nmod1 <- cmdstanr::cmdstan_model(\"binom_2.stan\")\nfit1 <- mod1$sample(data = data_list1, chains = 4, parallel_chains = 4,        \n                   refresh = 0, seed = 123)\n\n# Extracting posterior samples\nposterior_samples1 <- fit1$draws()\n\n# Plotting\ncolor_scheme_set(\"blue\")\n# mcmc_trace(posterior_samples, pars = c(\"p1\", \"p2\", \"rr\"), nrow = 3)\n\n# Plot relative risk distributions with no formatting\n# mcmc_areas(posterior_samples, pars = \"rr\", prob = 0.95)\n\n# print summary\nfit1$summary()\n\n# Correct extraction of relative risk samples\nrr_samples1 <- fit1$draws(variables = \"rr\")\nrr_vector1 <- as.vector(rr_samples1)  # Convert to a simple vector for easier handling\n\n# Calculating probabilities\nprob_rr_less_09 <- mean(rr_vector1 < 0.9)\nprob_rr_between_09_11 <- mean(rr_vector1 >= 0.9 & rr_vector1 <= 1.1)\nprob_rr_greater_11 <- mean(rr_vector1 > 1.1)\nprob_rr_less_08 <- mean(rr_vector1 < 0.8)\nprob_rr_less_10 <- mean(rr_vector1 < 1.0)\n\noptions(digits=2)\n# Print the probabilities\n# cat(\"Probability RR < 1.0 (P (statistical signifiance)): \", prob_rr_less_10, \n#   \"\\nProbability RR < 0.8: \", prob_rr_less_08, \n#   \"\\nProbability RR < 0.9: \", prob_rr_less_09,\n#   \"\\nProbability RR 0.9 to 1.1: \", prob_rr_between_09_11, \n#   \"\\nProbability RR > 1.1: \", prob_rr_greater_11, \"\\n\")\n```\n:::\n\n\n\n\n\n\n\n\n\nFor COLCOT, the probabilities of clinical benefit (RR \\< 0.9), practical equivalence ( 0.9 \\< RR \\< 1.1) and harm (RR \\> 1.1) are 89.98%, 9.85% and 0.18%, respectively. Again this can be shown graphically. Incidentally we can also calculate the probability of a clinical benefit exceeding a 20% reduction, 59.85%, as well as the probability of any benefit, 98.65%. Again these results may be dosplayed graphically where the area under the curve is proportional to each probability.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming rr_vector is already defined\nd <- density(rr_vector1)\ndensity_df <- data.frame(x = d$x, y = d$y)\n\n# Assign categories based on the x values\ndensity_df$category <- ifelse(density_df$x < 0.9, \"benefit\",\n                              ifelse(density_df$x <= 1.1, \"equivalence\", \"harm\"))\n\np <- ggplot(density_df, aes(x = x, y = y)) +\n  geom_area(data = subset(density_df, category == \"benefit\"), fill = \"green\", alpha = 0.5) +\n  geom_area(data = subset(density_df, category == \"equivalence\"), fill = \"yellow\", alpha = 0.5) +\n  geom_area(data = subset(density_df, category == \"harm\"), fill = \"red\", alpha = 0.5) +\n  geom_vline(xintercept = 0.9, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 1.1, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 1.0, color = \"blue\", size=1.5) +\n  labs(title=\"Density Plot of Relative Risk based on COLCOT\",\n       subtitle = \"with a vague (Beta(1,1) prior\") +\n  theme_classic() +\n  scale_x_continuous(expand = c(0, 0)) +  # No expansion on x-axis\n  scale_y_continuous(expand = c(0, 0)) +  # No expansion on y-axis\n  xlab(\"Relative Risk\") +\n  ylab(\"Density\")\n\np <- p + \n  annotate(\"text\", x = 0.64, y = max(density_df$y, na.rm = TRUE) * 0.8, label = \"Green\", color = \"green\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 0.79, y = max(density_df$y, na.rm = TRUE) * 0.73, label = \" = region of clinical benefit\", color = \"black\", size = 5) +\n  annotate(\"text\", x = 0.9, y = max(density_df$y, na.rm = TRUE) * 0.6, label = \"Yellow\", color = \"yellow\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 1.05, y = max(density_df$y, na.rm = TRUE) * 0.53, label = \" = region of practical equivalence\", color = \"black\", size = 5) +\n  annotate(\"text\", x = 1.15, y = max(density_df$y, na.rm = TRUE) * 0.4, label = \"Red\", color = \"red\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 1.10, y = max(density_df$y, na.rm = TRUE) * 0.35, label = \" = region of clinical harm\", color = \"black\", size = 5)\n\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\nThis figure explains possible different beliefs about the colchicine effect following COLCOT but before CLEAR. Some will be enthusiastic about a 90% probability of a clinical benefit (assuming a 10% reduction in RR is an appropriate clinical threshold). Those willing to accept this benefit threshold might classify themselves initially as \"colchicine believers\".Conversely others may be more conservative and want a larger reduction in RR, given the inconvenience, cost, and possible side effects of another medication. The probability of an at least 20% reduction is only 60%, not much better than a coin toss, underscoring their desire to perhaps wait for and even participate in, further studies (CLEAR) to better define any clinical benefits.\\\n<br> Accepting for the moment the validity of both trials, what should one now believe after CLEAR, if their prior belief had been determined by the COLCOT data. Here we simply repeat the Bayesian analysis but instead of a vague prior we use the COLCOT data.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# prior from COLCOT\n\nalpha1 = as.integer(2379 * 0.071)\nbeta1 <- 2379 - alpha1\nalpha2 = as.integer(2366 * 0.055)\nbeta2 <- 2366 - alpha2\n\n# Data for the model\ndata_list <- list(\n  n1 = 3534,\n  y1 = as.integer(3534 * 0.093),\n  n2 = 3528,\n  y2 = as.integer(3528 * 0.091),\n  alpha1 = alpha1,\n  beta1 = beta1,\n  alpha2 = alpha2,\n  beta2 = beta2\n)\n\n\n# Compile and fit the model\nmod <- cmdstan_model(\"binom_2_priorCOLCOT.stan\")\nfit <- mod$sample(data = data_list, chains = 4, parallel_chains = 4,        \n                  refresh = 0, seed = 123)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\nChain 3 finished in 0.0 seconds.\nChain 4 finished in 0.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Extracting posterior samples\nposterior_samples <- fit$draws()\n\n# Plotting\ncolor_scheme_set(\"blue\")\nmcmc_trace(posterior_samples, pars = c(\"p1\", \"p2\", \"rr\"), nrow = 3)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: The following arguments were unrecognized and ignored: nrow\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plot relative risk distributions with no formatting\n# mcmc_areas(posterior_samples, pars = \"rr\", prob = 0.95)\n\n# print summary\nfit$summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 10\n  variable       mean    median      sd     mad       q5      q95  rhat ess_bulk\n  <chr>         <dbl>     <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n1 lp__     -3297.      -3.30e+3 0.980   0.667   -3.30e+3 -3.30e+3  1.00    1915.\n2 p1           0.0839   8.38e-2 0.00355 0.00348  7.81e-2  8.97e-2  1.00    3516.\n3 p2           0.0765   7.65e-2 0.00343 0.00349  7.09e-2  8.23e-2  1.00    3237.\n4 rr           0.914    9.13e-1 0.0567  0.0576   8.23e-1  1.01e+0  1.00    3281.\n# ℹ 1 more variable: ess_tail <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# Correct extraction of relative risk samples\nrr_samples <- fit$draws(variables = \"rr\")\nrr_vector <- as.vector(rr_samples)  # Convert to a simple vector for easier handling\n\n# Calculating probabilities\nprob_rr_less_09 <- mean(rr_vector < 0.9)\nprob_rr_between_09_11 <- mean(rr_vector >= 0.9 & rr_vector <= 1.1)\nprob_rr_greater_11 <- mean(rr_vector > 1.1)\nprob_rr_less_08 <- mean(rr_vector < 0.8)\n\n# Print the probabilities\ncat(\"Probability RR < 0.9: \", prob_rr_less_09, \"\\nProbability RR 0.9 to 1.1: \", prob_rr_between_09_11, \"\\nProbability RR > 1.1: \", prob_rr_greater_11, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProbability RR < 0.9:  0.41 \nProbability RR 0.9 to 1.1:  0.59 \nProbability RR > 1.1:  0.0013 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\nUnderstanding these results is facilitated with graphical presentations where it is noted that this posterior distribution with the COLOT informative prior is a weighted average between the COLCOT probability distributions and the CLEAR likelihood distirbution.\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming rr_vector is already defined\nd <- density(rr_vector)\ndensity_df <- data.frame(x = d$x, y = d$y)\n\n# Assign categories based on the x values\ndensity_df$category <- ifelse(density_df$x < 0.9, \"benefit\",\n                              ifelse(density_df$x <= 1.1, \"equivalence\", \"harm\"))\n\np <- ggplot(density_df, aes(x = x, y = y)) +\n  geom_area(data = subset(density_df, category == \"benefit\"), fill = \"green\", alpha = 0.5) +\n  geom_area(data = subset(density_df, category == \"equivalence\"), fill = \"yellow\", alpha = 0.5) +\n  geom_area(data = subset(density_df, category == \"harm\"), fill = \"red\", alpha = 0.5) +\n  geom_vline(xintercept = 0.9, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 1.1, linetype = \"dashed\", color = \"black\") +\n  geom_vline(xintercept = 1.0, color = \"blue\", size=1.5) +\n  labs(title=\"Density Plot of Relative Risk based on CLEAR OASIS\",\n       subtitle = \"with an informative (COLCOT) prior\") +\n  theme_classic() +\n  scale_x_continuous(expand = c(0, 0)) +  # No expansion on x-axis\n  scale_y_continuous(expand = c(0, 0)) +  # No expansion on y-axis\n  xlab(\"Relative Risk\") +\n  ylab(\"Density\")\n\np <- p + \n  annotate(\"text\", x = 0.80, y = max(density_df$y, na.rm = TRUE) * 0.6, label = \"Green\", color = \"green\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 0.86, y = max(density_df$y, na.rm = TRUE) * 0.56, label = \" = region of clinical benefit\", color = \"black\", size = 5) +\n  annotate(\"text\", x = 0.8, y = max(density_df$y, na.rm = TRUE) * 0.8, label = \"Yellow\", color = \"yellow\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = .90, y = max(density_df$y, na.rm = TRUE) * 0.76, label = \" = region of practical equivalence\", color = \"black\", size = 5) +\n  annotate(\"text\", x = 1.00, y = max(density_df$y, na.rm = TRUE) * 0.4, label = \"Red\", color = \"red\", size = 5, fontface = \"bold\") +\n  annotate(\"text\", x = 1.07, y = max(density_df$y, na.rm = TRUE) * 0.33, label = \" = region of clinical harm\", color = \"black\", size = 5)\n\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n\n\nLet's return to the CLEAR PI who was a \"believer\" prior to his study but not after seeing the CLEAR data. If the COLCOT RCT results were responsible for his positive prior beliefs, this analyse suggests after CLEAR there remains a 40.9% probability of a clinically meaningful decrease in CV risk with colchicine, a 58.98% probability of clinical equivalence with placebo and virtually no chance of a clinically meaningful increase in cardiovascular outcomes.\\\n<br> Of course, if a clinician had an clinical cutpoint for efficacy of RR \\< 0.80 then it does indeed seem reasonable, based on the totality of the evidence to be a \"non-believer\" as the probability of decreased cardiovascular outomces is less than 1.77%. However this would imply that their prior efficacy belief should also be referenced to a probability of RR \\< 0.80 which for COLCOT was only 60%. This seems a fairly modest probability to have been a strong \"believer\" in this therapy before the current study.\\\n<br> This demonstrates that an intuitive reconciliation of prior and posterior beliefs can be difficult and is not helped by dichotomization. Moreover, clinicians may be overly influenced by the last trial, particularly if they were intimately involved in it. The probabilistically correct harmonization of all avalaible evidence can only be assured with a Bayesian analysis, avoiding these cognitive issues.\\\n\n### Bayesian Meta-analysis\n\nThis updating of prior beiliefs has an advantage of being temporally consistent with the availability of the data and mirrors human sequential learning. Very similar results can be reached when a Bayesian random effects (hierarchical) meta-analysis is performed in the case where data temporality is not a factor. Hierarchical models represent a compromise between complete pooling (fixed effect) or no pooling if the studies are considered completely independent. Individual studies are treated as part of a larger population of studies and allows for \"shrinkage\", where estimates for individual studies are partially \"pulled\" toward the overall mean effect across studies.\\\n<br>For the colchicine example, this model accounts for both within and between study variability producing pooled mean estimates that integrate information from both studies while acknowledging that study effects might vary. This model also can provide the predictive interval for the next study from the super population of possible studies. As with the preceding analyses, in the Bayesian paradigm all parameters require an initial priors. In this case, a prior is required for the mean estimate and the population variation and you have assumed vague priors with a range between 0.14 to 7.4 (N(0,1) on the log scale). The results of this meta-analysis are displayed in the following figure\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hierarchical meta-analytical data prep and plot using brms package\n# slightly more informative priors N(0,1) than the default priors\nlibrary(tidybayes); library(brms); library(posterior); library(tidyverse)\n\n# data prep\ntotal <- matrix(c(322, (3528-322), 327, (3534-327)), nrow = 2, byrow = TRUE, dimnames = list(c(\"colchicine\", \"placebo\"), c(\"Event\", \"No event\")))\nepiR::epi.2by2(dat = as.table(total), method = \"cohort.count\", conf.level = 0.95, units = 100, outcome = \"as.columns\")\n\ncol_df <- data.frame(study=c(\"CLEAR\", \"COLCOT\"), n_col=c(3528,2366), e_col=c(322,130), n_ctl=c(3534,2379), e_ctl=c(327,169))\ndat <- metafor::escalc(measure=\"RR\", ai=e_col, n1i = n_col, ci=e_ctl,  n2i =n_ctl, data=col_df)\n\n# standard (non-bayesian) random effects model\nlibrary(metafor)\nme.fe <- rma(dat$yi, sei=sqrt(dat$vi), method = \"FE\") # exponentiation c(exp(me.fe$b), exp(me.fe$ci.lb), exp(me.fe$ci.ub))\nme.re <- rma(dat$yi, sei=sqrt(dat$vi), method = \"REML\") # exponentiation c(exp(me.re$b), exp(me.re$ci.lb), exp(me.re$ci.ub))\nplot_Plato <- meta::metabin(col_df$e_col, col_df$n_col, col_df$e_ctl, col_df$n_ctl, sm=\"RR\", method =\"I\", studlab=dat$Region, prediction=TRUE, comb.random =TRUE)\nprint(summary(plot_Plato,prediction=TRUE), digits=2)\n\nmeta::forest(plot_Plato, studlab = col_df$study)\n\n# Time to go bayesian\n# Specify priors for mu and tau (could also ignore and use brms defaults,  set_prior(\"normal(0,10)\", class = \"sd\"))\nprior <- c(\n  set_prior(\"normal(0, 1)\", class = \"Intercept\"),      # Matches Stan's prior for mu\n  set_prior(\"normal(0, 1)\", class = \"sd\")             # Matches Stan's prior for tau\n)\n\n# Fit the model with custom priors\nbrm_out <- brm(\n  yi | se(sqrt(vi)) ~ 1 + (1|study), \n  data = dat, \n  iter = 20000, warmup = 2000, cores = 4, refresh = 0,\n  control = list(adapt_delta = 0.99), # Improve convergence\n  prior = prior,                     # Apply the custom priors\n  seed = 123\n)\n\nsummary(brm_out)\n\n\n# Extract posterior samples as_draws() is another option\npost <- brm_out %>%\n  spread_draws(b_Intercept, r_study[study,]) %>%  # variables(brm_out)\n  median_qi(condition_mean = b_Intercept + r_study, .width = c(.95)) %>% \n  rename(lower = .lower, rr = condition_mean, upper = .upper) %>% \n  select(study, rr, lower, upper) # Keep relevant columns for study-level output\n\npost[,c(2:4)] <- apply(post[,c(2:4)],2,exp) # change from log(OR) to OR\n\n# Extract posterior draws with posterior package and as_draws_df\ndraws <- as_draws_df(brm_out)  # variables(draws) to get names\n\n# Mean and 95% CI for the mean effect\nmean_intercept <- mean(draws$b_Intercept) # Mean effect (Intercept)\nci_intercept <- quantile(draws$b_Intercept, probs = c(0.025, 0.975)) # Between-study standard deviation\nsigma <- draws$sigma                       # Residual standard deviation\n\n# Transform to OR scale\nmean_or <- exp(mean_intercept)\nci_or <- exp(ci_intercept)\n\n# Simulate predicted values for the next study (log scale)\npredicted_values <- rnorm(n = length(draws$b_Intercept), mean = mean_intercept,\n                          sd = sqrt(draws$sd_study__Intercept^2 + sigma^2)\n)\npredicted_ci <- quantile(predicted_values, probs = c(0.025, 0.975))\n\n# Transform predicted values to OR scale\npredicted_mean_or <- exp(mean(predicted_values))\npredicted_ci_or <- exp(predicted_ci)\n\n\n#########\n\ndat <- dat %>% \n  mutate(rr=yi, upper= yi +1.96*sqrt(vi), lower= yi - 1.96*sqrt(vi)) %>% \n  select(study,rr,lower,upper)\ndat[,c(2:4)] <- apply(dat[,c(2:4)],2,exp)\n\n\npost <- rbind(post, dat)\n\npost$lab <- rep(c(\"Theta\", \"Y\"), each = 2)\npost$id <- c(1,2,1,2)\n\n# Create the data frame with desired structure for hierarchical plotting\n# Add overall mean and next study\nresults_df <- tibble(\n  study = c(\"Mean\", \"Predicted Next Study\"),\n  lower = c(ci_or[1], predicted_ci_or[1]),\n  rr = c(mean_or, predicted_mean_or),\n  upper = c(ci_or[2], predicted_ci_or[2])\n)\nresults_df$lab <- c(\"Mean\", \"Next\")\nresults_df$id <- c(3,4)\n\npost <- rbind(post, results_df)\n\ng1 <- ggplot(post, aes(x = forcats::fct_rev(study), y = rr, ymin = lower, ymax = upper, col = lab)) +  \n  geom_pointrange(aes(col = lab), position = position_dodge(width = 0.50)) +\n  coord_flip() + geom_hline(aes(yintercept = 0.895), lty = 2) +  xlab(\"\") + \n  ylab(\"\")  + theme(legend.position=\"bottom\") + geom_hline(aes(yintercept = 1), lty = 1) +\n  scale_colour_discrete(name=\"\", \n                        labels = c(\"Theta\" = bquote(\"Random effect \\n(hierarchical \\\"shrinking\\\"):\"~exp(theta[J])~\" \"),\n                                   \"Y\"= bquote(\"Relative risk \\n(observed data):\"~exp(Y[J])))) +\n  labs(title = \"Bayesian forest plot of cholcicine trials\",\n       subtitle = \"Observed and hierarchical individual trial results\",\n       caption = \"Prior tau = normal(0, 1.0)\n\\nMean prior = normal(0, 1.0) |\") +\n  theme_bw()\n\nggsave(g1,\"output/brms_hier.png\", dpi = 600, width = 8)\n\n########## Reproduce same table as from Stan\n# Summarize study-level estimates\n\n# Extract and summarize overall mu\nmu_values <- brm_out %>% spread_draws(b_Intercept) %>% pull(b_Intercept)\noverall_mu <- tibble(study = \"Overall (mu)\", rr = mean(mu_values, na.rm = TRUE),\n                     lower = quantile(mu_values, 0.025, na.rm = TRUE),\n                     upper = quantile(mu_values, 0.975, na.rm = TRUE))\n\n# Extract and summarize overall tau\ntau_values <- brm_out %>% spread_draws(sd_study__Intercept) %>% pull(sd_study__Intercept)\noverall_tau <- tibble(study = \"Overall (tau)\", rr = mean(tau_values, na.rm = TRUE),\n                      lower = quantile(tau_values, 0.025, na.rm = TRUE),\n                      upper = quantile(tau_values, 0.975, na.rm = TRUE))\n\n# Combine all summaries\noptions(digits = 3)\ntemp <- post[c(1:2),c(1:4)]\ntemp[,c(2:4)] <- apply(temp[,c(2:4)],2,log) \noverall_post <- bind_rows(temp, overall_mu, overall_tau)\noverall_post\n\n# probability of > 10% reduction, log(.9) = -0.11\n# mean sd = (.653 + .860)/3.92 = 0.386\n# pnorm(-.11, -.111, .39) = 0.51 or more precisely\n# pnorm(.9, 0.896, 0.382) = 0.504 from post (1.921-.423)/3.92 = 0.382\n```\n:::\n\n\n\n\n\n\n\n\n\n![](/output/brms_hier.png) The figure demonstrates several key points;\\\n1. there is shrinkage of each observed trial result towards the global mean\\\n2. the overall mean is represented by a normal(0.896, 0.386) which gives a 50% probability of a colchicine benefit exceeding a 10% reduction in CV outcomes\\\n3. the probability result is, as expected, virtually identical to that obtained from the sequential Bayesian approach above.\n\n### A meta-analysis with a single trial\n\nWhile random effects meta-analyses account for both within study and between study variability, a questions arises as to how to proceed if there is only one study? A paradoxical situation arises if the unmeasured between study uncertainty a sinlge trial is ignored whereby with less evidence better precision in estimating the mean population effect is observed, than when more evidence in the form of multiple studies are available.\\\n<br> Compared to naively ignoring this between study variation, a recent study showed an empirical Bayes approach using as a prior the distribution of treatment effects and heterogeneity from 1,636 meta-analyses in the Cochrane Database of Systematic Reviews (CDSR) showed important reductions in the mean squared error both for estimating the study-level and population-level effects equivalent to more than doubling the isolated study sample size.[@RN7045]\\\nIn the CLEAR example, this novel approach gives essentially the same probabilities as the previous analysis with vague priors as the CLEAR data set is quite large over riding both the vaue and empirical priors.\n\n## Conclusion\n\nClinicians are often faced with \"conflicting\" trial evidence. However if the trials are of equal high quality, it is important to first appreciate that these conflicts are often illusory arising from the incorrect comparisons of statistical significance. Systematic reviews and meta-analyses of prior evidence is now often demanded by funders before consideration of funding. Yet there is no similar request for a synthesis of the evidence after a trial is compeleted. Rather current incentives favor that each trial is interpreted individually. However, as demonstrated by the recent colchicine trials, this approach can lead to a flip flopping of beliefs that do not approach the current true state of knowledge. Bayesian techniques can address these issues by allowing the incorportation of past evidence and properly accounting for associated unceertainties thereby raising the quality of clinical trial interpretations\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}